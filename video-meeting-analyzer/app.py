# app.py

import streamlit as st
import pandas as pd
from analyzer import extract_audio, transcribe_audio, create_search_index, semantic_search, TEMP_DIR
import os

# --- –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(page_title="Video Meeting Analyzer", page_icon="üé•", layout="wide")

st.title("üé• Video Meeting Analyzer")
st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—å –≤—Å—Ç—Ä–µ—á–∏, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—É—é —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞ –ø–æ –µ—ë —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.")

# --- –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (–¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –¥–µ–π—Å—Ç–≤–∏—è–º–∏) ---
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
    st.session_state.segments_df = None
    st.session_state.search_index = None

# --- –®–ê–ì 1: –ó–ê–ì–†–£–ó–ö–ê –§–ê–ô–õ–ê ---
st.header("1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à–µ –≤–∏–¥–µ–æ")
uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª (MP4, MOV, AVI)", type=["mp4", "mov", "avi", "mkv"])

if uploaded_file is not None:
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
    video_path = os.path.join(TEMP_DIR, uploaded_file.name)
    with open(video_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    st.video(video_path)

    # --- –®–ê–ì 2: –ê–ù–ê–õ–ò–ó ---
    if st.button("üîç –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ", type="primary"):
        with st.spinner("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ. –ò–¥–µ—Ç –∞–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è."):
            try:
                # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ
                st.write("–®–∞–≥ 1/4: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ...")
                audio_path = extract_audio(video_path)
                if not audio_path:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ.")
                    st.stop()
                
                # 2. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
                st.write("–®–∞–≥ 2/4: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Ä–µ—á–∏ (–º–æ–¥–µ–ª—å Whisper)...")
                segments = transcribe_audio(audio_path)
                if not segments:
                    st.error("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –Ω–µ –¥–∞–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.")
                    st.stop()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –≤ DataFrame –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                st.session_state.segments_df = pd.DataFrame(segments)

                # 3. –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
                st.write("–®–∞–≥ 3/4: –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (FAISS)...")
                st.session_state.search_index = create_search_index(segments)
                
                st.write("–®–∞–≥ 4/4: –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
                st.session_state.analysis_complete = True
                st.success("–í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ! –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–∫–∞—Ç—å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É.")

            except Exception as e:
                st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {e}")

# --- –®–ê–ì 3: –ü–û–ò–°–ö –ò –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ---
if st.session_state.analysis_complete:
    st.header("2. –ü–æ–∏—Å–∫ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é –≤—Å—Ç—Ä–µ—á–∏")
    search_query = st.text_input(
        "–ß—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ –Ω–∞–π—Ç–∏? (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–æ–±—Å—É–∂–¥–µ–Ω–∏–µ –±—é–¥–∂–µ—Ç–∞' –∏–ª–∏ '–∫—Ç–æ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç?')",
        ""
    )

    if search_query:
        results = semantic_search(search_query, st.session_state.search_index, st.session_state.segments_df)
        
        st.subheader("–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã:")
        if not results:
            st.warning("–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        else:
            for res in results:
                st.markdown(f"**üïí `{res['timestamp']}`** - {res['text']}")
                st.progress(res['similarity'], text=f"–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {res['similarity']:.2f}")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
    with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—É—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é"):
        full_transcript = " ".join(st.session_state.segments_df['text'])
        st.write(full_transcript)
